<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Contrastive Learning & Generative Adversarial Network (GANs) | Aleksandra T. Ma</title>
    <meta name="author" content="Aleksandra T. Ma" />
    <meta name="description" content="Latent Space, Contrastive Learning & GANs " />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/favicon.jpeg"/>
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/blog/2022/cont-gan/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Aleksandra </span>T. Ma</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">cv</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- _layouts/post.html -->

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Contrastive Learning &amp; Generative Adversarial Network (GANs)</h1>
    <p class="post-meta">November 28, 2022</p>
    <p class="post-tags">
      <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a>
        ·  
        <a href="/blog/tag/tech">
          <i class="fas fa-hashtag fa-sm"></i> tech</a>  
          
        ·  
        <a href="/blog/category/beginners-guide">
          <i class="fas fa-tag fa-sm"></i> beginners-guide</a>  
          

    </p>
  </header>

  <article class="post-content">
    <h3 id="latent-space">Latent Space</h3>

<ul>
  <li>
    <p>Definition: Representation of compressed data</p>
  </li>
  <li>
    <p>Data compression: process of encoding information using fewer bits than the original representation</p>
  </li>
</ul>

<p><img src="/assets/img/deep-learning/image1.png" alt="latent-space" width="100%" style="padding-bottom:0.5em;"></p>

<p>Ekin Tiu has a Medium article about why it is called latent “space” <a href="https://towardsdatascience.com/understanding-latent-space-in-machine-learning-de5a7c687d8d" target="_blank" rel="noopener noreferrer">here</a></p>

<ul>
  <li>
    <p>Tasks where latent space is necessary</p>

    <ul>
      <li>
        <p>Representation learning:</p>

        <ul>
          <li>
            <p>Definition: set of techniques that allow a system to discover the representations needed for feature detection or classification from raw data</p>
          </li>
          <li>
            <p>Latent space representation of our data <strong>must</strong> contain all the important info (<strong>features</strong>) to represent our original data input</p>
          </li>
        </ul>
      </li>
      <li>
        <p>Manifold learning (subfield of representation learning):</p>

        <ul>
          <li>
            <p>Definition: groups or subsets of data that are “similar” in some way in the latent space, that does not quite show in the higher dimensional space.</p>
          </li>
          <li>
            <p>Manifolds just mean groups of similar data</p>
          </li>
        </ul>
      </li>
      <li>
        <p>Autoencoders and Generative Models</p>

        <ul>
          <li>
            <p>Autoencoders: a neural network that acts an identify function, that has both an encoder and a decoder</p>
          </li>
          <li>
            <p>We need the model to compress the representation (<strong>encode</strong>) in a way that we can accurately reconstruct it (<strong>decode</strong>).</p>

            <ul>
              <li>i.e. image in image out, audio in audio out
  <img src="/assets/img/deep-learning/image2.png" alt="auto-encoders" width="100%" style="padding-bottom:0.5em;">
</li>
            </ul>
          </li>
          <li>
            <p>Generative models: interpolate on latent space to generate “new” image</p>

            <ul>
              <li>
                <p>Interpolate: make estimations of independent variables if the independent variable takes on a value in between the range</p>
              </li>
              <li>
                <p>Example: if chair images have 2D latent space vectors as [0.4, 0.5] and [0.45, 0.45], whereas the table has [0.6, 0.75]. Then to generate a picture that is a morph between a chair and a desk, we would <em>sample points in latent space between</em> the chair cluster and the desk cluster.</p>
              </li>
              <li>
                <p>Diff between discriminative and generative:</p>

                <ul>
                  <li>
                    <p>Generative can generate new data instances, capture the joint probability of p(X,Y) or p(X) if Y does not exist</p>
                  </li>
                  <li>
                    <table>
                      <tbody>
                        <tr>
                          <td>Discriminative models classifies instances into different labels. It captures p(Y</td>
                          <td>X) -&gt; given the image, how likely is it a cat?</td>
                        </tr>
                      </tbody>
                    </table>
                  </li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="contrastive-learning-with-simclrv2">Contrastive Learning with SimCLRv2</h3>

<ul>
  <li>
    <p>Definition: a technique that learns general features of a dataset <strong>without labels</strong> by teaching the model which data points are similar or different.</p>

    <ul>
      <li>
        <p>Happens <strong>before</strong> classification or segmentation.</p>
      </li>
      <li>
        <p>A type of self-supervised learning. The other is non-contrastive learning.</p>
      </li>
      <li>
        <p>Can significantly improve model performance even when only a fraction of the dataset is labeled.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Process:
  <img src="/assets/img/deep-learning/image3.png" alt="contrastive" width="100%" style="padding-bottom:0.5em;"></p>

    <ol>
      <li>
        <p><strong>Data Augmentation</strong> through 2 augmentation combos (i.e. crop + resize + recolor, etc.)</p>
      </li>
      <li>
        <p><strong>Encoding:</strong> Feed the two augmented images into deep learning model to create <strong>vector representations</strong>.</p>

        <ul>
          <li>
<strong>Goal</strong> is to train the model to output similar representations for similar images</li>
        </ul>
      </li>
      <li>
        <p><strong>Minimize loss:</strong> Maximize the similarity of the two vector representations by minimizing a contrastive loss function</p>

        <ul>
          <li>
            <p>Goal is to <strong>quantify the similarity</strong> of the two vector representations, then <strong>maximize the probability</strong> that two vector representations are similar.</p>
          </li>
          <li>We use <em>cosine similarity</em> as an example to quantify similarities: the angle between the two vectors in space. The closer they are, the bigger the similarity score
 <img src="/assets/img/deep-learning/image4.png" alt="cosine-sim" width="100%" style="padding-bottom:0.5em;">
</li>
          <li>Next compute the <em>probability</em> with softmax:
  <img src="/assets/img/deep-learning/image5.png" alt="softmax" width="100%" style="padding-bottom:0.5em;">
</li>
          <li>Last we use -log() to make it a loss function so that we are minimizing this value, which corresponds to maximizing the probability that two pairs are similar
  <img src="/assets/img/deep-learning/image6.png" alt="cross-entropy" width="100%" style="padding-bottom:0.5em;">
</li>
        </ul>
      </li>
    </ol>
  </li>
</ul>

<h3 id="generative-adversarial-network-2014">Generative Adversarial Network, 2014</h3>

<p>Machine Learning Course by Google Developers <a href="https://developers.google.com/machine-learning/gan/loss" target="_blank" rel="noopener noreferrer">here</a></p>

<ul>
  <li>
    <p>Definition (high level): create new data instances that resemble your training data</p>
  </li>
  <li>
    <p>High level working mechanism: GANs achieve this level of realism by pairing a <strong>generator</strong>, which learns to produce the target output, with a <strong>discriminator</strong>, which learns to distinguish true data from the output of the generator. The generator tries to fool the discriminator, and the discriminator tries to keep from being fooled.</p>

    <ul>
      <li>See the diagram below
  <img src="/assets/img/deep-learning/image7.png" alt="gan" width="100%" style="padding-bottom:0.5em;">
</li>
    </ul>
  </li>
</ul>

<h5 id="step-1-discriminator-trains-for-one-or-more-epochs">Step 1. Discriminator trains for one or more epochs.</h5>

<p>The discriminator takes input from real images and the fake images the generator outputs, update its weights through backpropagation to distinguish between real and fake data.</p>

<p>Generator does not update its weight during this period, and discriminator ignores generator loss in this round.
<img src="/assets/img/deep-learning/image8.png" alt="gan-discriminator" width="100%" style="padding-bottom:0.5em;"></p>

<h5 id="step-2-generator-trains-for-one-or-more-epochs">Step 2. Generator trains for one or more epochs.</h5>

<p><img src="/assets/img/deep-learning/image9.png" alt="gan-generator" width="100%" style="padding-bottom:0.5em;"></p>

<ul>
  <li>
    <p>Goal is to generate data that the discriminator will classify as real, so the generator loss penalizes the generator for failing to fool the discriminator.</p>

    <ul>
      <li>This requires the generator training to incorporate discriminator. How it involves discriminator is using it to feed it the generator output and derive the generator loss.</li>
    </ul>
  </li>
  <li>
    <p>When generator trains, discriminator stays put and does not update weights.</p>
  </li>
  <li>
    <p>Procedure:</p>

    <ul>
      <li>
        <p>Sample random noise that we feed into the generator. The generator will transform this into meaningful output</p>

        <ul>
          <li>the distribution of the noise doesn’t matter much; could also be non-random input</li>
        </ul>
      </li>
      <li>
        <p>Produce generator output from sampled random noise</p>
      </li>
      <li>
        <p>Get discriminator’s Real or Fake classification for generator output</p>
      </li>
      <li>
        <p>Calculate loss from discriminator classification (generator loss)</p>
      </li>
      <li>
        <p>Backpropagate through both the discriminator and generator to obtain gradients</p>
      </li>
      <li>
        <p>Use gradients to change <strong>only</strong> the generator weights.</p>
      </li>
    </ul>
  </li>
</ul>

<h5 id="step-3-repeat-step-1-and-2-to-alternate-training">Step 3. Repeat step 1 and 2 to alternate training</h5>

<ul>
  <li>
    <p>Convergence: when discriminator classification has a 50% accuracy (it can’t tell between a true and a fake)</p>

    <ul>
      <li>
        <p>This poses a problem: if discriminator feedback becomes 50% (near random), then the generator is training on useless feedback, which in turn affects its own quality</p>
      </li>
      <li>
        <p>GAN convergence is a fleeting, instead of stable, state</p>
      </li>
    </ul>
  </li>
</ul>

<h5 id="loss-functions">Loss Functions</h5>

<ul>
  <li>
    <p>Goal: capture the difference between the distributions of “real” data and “fake” data generated by the generator</p>

    <ul>
      <li>
        <p>Still ongoing research</p>
      </li>
      <li>
        <p>Example: minimax loss (used in og GAN paper), Wasserstein loss (used for TF-GAN estimator)</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Minimax Loss:</strong></p>

    <ul>
      <li>
        <p>It’s the same formula that the discriminator and generator are optimizing over. <strong>Discriminator maximize, generator minimize</strong></p>

        <p>Ex[log(D(x))]+Ez[log(1−D(G(z)))]</p>

        <p>In this function:</p>

        <ul>
          <li>
            <p><code class="language-plaintext highlighter-rouge">D(x)</code> is the discriminator’s estimate of the probability that real data instance x is real.</p>
          </li>
          <li>
            <p>Ex is the expected value over all real data instances.</p>
          </li>
          <li>
            <p><code class="language-plaintext highlighter-rouge">G(z)</code> is the generator’s output when given noise z.</p>
          </li>
          <li>
            <p><code class="language-plaintext highlighter-rouge">D(G(z))</code> is the discriminator’s estimate of the probability that a fake instance is real.</p>
          </li>
          <li>
            <p>Ez is the expected value over all random inputs to the generator (in effect, the expected value over all generated fake instances G(z)).</p>
          </li>
          <li>
            <p>The formula derives from the <a href="https://developers.google.com/machine-learning/glossary#cross-entropy" target="_blank" rel="noopener noreferrer">cross-entropy</a> between the real and generated distributions.</p>
          </li>
        </ul>

        <p>The generator can’t directly affect the <code class="language-plaintext highlighter-rouge">log(D(x))</code> term in the function, so, for the generator, minimizing the loss is equivalent to minimizing <code class="language-plaintext highlighter-rouge">log(1 - D(G(z)))</code>.</p>
      </li>
      <li>
        <p><strong>Caveat-&gt; Vanishing Gradients</strong></p>

        <ul>
          <li>
            <p>The generator can fail due to vanishing gradients and the GAN might get stuck in the early stages if the discriminator is too good. Two remedies:</p>

            <ul>
              <li>
                <p>Modified minimax loss: the original paper suggests to modify the generator loss so that the generator tries to maximize log D(G(z))</p>
              </li>
              <li>
                <p>Wasserstein loss introduced below is designed to prevent vanishing gradients</p>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Wasserstein Loss</strong></p>

    <ul>
      <li>
        <p><strong>! Modification of GAN Scheme:</strong> discriminator does not classify instances or produce probabilities, but instead it produces a number. We call it critic instead of discriminator</p>

        <ul>
          <li>
            <p>For real instances: outputs a really big number</p>
          </li>
          <li>
            <p>For fake instances: outputs a really small number</p>
          </li>
          <li>
            <p>Requires the weights throughout GAN to be clipped so that they remain within a constrained range</p>
          </li>
        </ul>
      </li>
      <li>
        <p>Critic Loss: D(x) - D(G(z))</p>

        <ul>
          <li>The discriminator maximizes this function, they want the difference between the real and the fake to be as big as possible</li>
        </ul>
      </li>
      <li>
        <p>Generator Loss: D(G(z))</p>

        <ul>
          <li>The generator maximizes this function because they want the discriminator to think what they generated is a real instance</li>
        </ul>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">D(x)</code> is the critic’s output for a real instance.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">G(z)</code> is the generator’s output when given noise z.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">D(G(z))</code> is the critic’s output for a fake instance.</p>
      </li>
      <li>
        <p>The output of critic D does <em>not</em> have to be between 1 and 0.</p>
      </li>
      <li>
        <p>The formulas derive from the <a href="https://wikipedia.org/wiki/Earth_mover%27s_distance" target="_blank" rel="noopener noreferrer">earth mover distance</a> between the real and generated distributions.</p>
      </li>
      <li>
        <p>WassersteinGANs is less vulnerable to getting stuck than minimaxGANs, and avoid problems with vanishing gradients</p>
      </li>
    </ul>
  </li>
</ul>

<h5 id="common-problems">Common Problems</h5>

<ul>
  <li>
    <p>Vanishing Gradients:</p>

    <ul>
      <li>If discriminator is too good, the generator training can fail due to vanishing gradients. Remedy is through 1) Wasserstein loss 2) modified minimax loss</li>
    </ul>
  </li>
  <li>
    <p>Mode collapse: usually happens when the discriminator gets stuck in local minima.</p>

    <ul>
      <li>
        <p>Mode collapse describes the scenario where each iteration of generator over-optimizes for a particular discriminator, so the generators rotate through a small set of output types. This is against what we want: for generator to produce a wide variety of outputs.</p>
      </li>
      <li>
        <p>Remedy:</p>

        <ul>
          <li>
            <p>Wasserstein loss: designed to avoid vanishing gradient/discriminator being stuck in a local minima</p>
          </li>
          <li>
            <p>Unrolled GANs: uses a generator loss function that not only incorporates the current discriminator’s classification, but also the outputs of future discriminator versions.</p>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Failure to convergence: discriminator can’t tell the diff between real and fake, so generator trains on junk feedback. Two remedies:</p>

    <ul>
      <li>
        <p>Adding noise to discriminator inputs</p>
      </li>
      <li>
        <p>Penalizing discriminator weights</p>
      </li>
    </ul>
  </li>
</ul>

  </article>

</div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2022 Aleksandra T. Ma. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. All photos &amp; opinions my own.
Last updated: November 28, 2022.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>
