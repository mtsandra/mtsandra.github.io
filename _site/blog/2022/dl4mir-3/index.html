<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Deep Learning for Music Information Retrieval – Pt. 3 (CNN) | Aleksandra T. Ma</title>
    <meta name="author" content="Aleksandra T. Ma" />
    <meta name="description" content="Part 3 introduces convolution and convolutional neural network." />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/favicon.jpeg"/>
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/blog/2022/dl4mir-3/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Aleksandra </span>T. Ma</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">cv</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- _layouts/post.html -->

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Deep Learning for Music Information Retrieval – Pt. 3 (CNN)</h1>
    <p class="post-meta">October 22, 2022</p>
    <p class="post-tags">
      <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a>
        ·  
        <a href="/blog/tag/tech">
          <i class="fas fa-hashtag fa-sm"></i> tech</a>  
          <a href="/blog/tag/music">
          <i class="fas fa-hashtag fa-sm"></i> music</a>  
          <a href="/blog/tag/tutorial">
          <i class="fas fa-hashtag fa-sm"></i> tutorial</a>  
          
        ·  
        <a href="/blog/category/Deep-Learning">
          <i class="fas fa-tag fa-sm"></i> Deep-Learning</a>  
          <a href="/blog/category/MIR">
          <i class="fas fa-tag fa-sm"></i> MIR</a>  
          

    </p>
  </header>

  <article class="post-content">
    <p>This series is inspired by my recent efforts to learn about applying deep learning in the music information retrieval field. I attended a two-week <a href="https://ccrma.stanford.edu/workshops/deep-learning-for-music-information-retrieval-I" target="_blank" rel="noopener noreferrer">workshop</a> on the same topic at Stanford’s Center for Computer Research in Music and Acoustics, which I highly recommend to anyone who is interested in AI + Music. This series is guided by Choi et al.’s 2018 <a href="https://arxiv.org/abs/1709.04396" target="_blank" rel="noopener noreferrer">paper</a>, <em>A Tutorial on Deep Learning for Music Information Retrieval</em>.</p>

<p>It will consist of four parts: Background of Deep Learning, Audio Representations, Convolutional Neural Network, Recurrent Neural Network. This series is only a beginner’s guide.</p>

<p>My intent of creating this series is to break down this topic in a bullet point format for easy motivation and consumption.</p>

<p><br></p>

<hr>

<p><br></p>

<h2 id="convolution">Convolution</h2>

<p>I struggled for a long time to understand what convolution means. Turns out it can be explained from different perspectives. Chris Olah has this amazing <a href="https://colah.github.io/posts/2014-07-Understanding-Convolutions/" target="_blank" rel="noopener noreferrer">explanation</a> of convolution from probability’s perspective.</p>

<p><img src="/assets/img/dl4mir/image13.png" alt="convolutions" width="80%" style="padding-bottom:0.5em;"> <br>
Mathematical definition: t here can be treat as a constant that changes. So in the context of signal processing, it can be thought of filter g is reversed, and then slides along the horizontal axis. For every position, we calculate the area of the intersection between f and g. This area is the convolution value at the specific position. See the gif from convolution Wikipedia page. <br><br>
<img src="/assets/img/dl4mir/moving.gif" alt="convolutions" width="80%" style="padding-bottom:0.5em;"><br></p>

<p><img src="/assets/img/dl4mir/image14.png" alt="convolutions" width="80%" style="padding-bottom:0.5em;"><br>
In convolutional neural networks, the filters are not reversed. It is technically called cross-correlation.</p>

<p><img src="/assets/img/dl4mir/image15.png" alt="convolutions" width="80%" style="padding-bottom:0.5em;"><br></p>

<p><br><br></p>

<h3 id="how-2d-convolutional-network-works-with-multiple-channels">How 2D Convolutional Network works with multiple channels</h3>

<p><img src="/assets/img/dl4mir/image16.png" alt="formula" width="80%" style="padding-bottom:0.5em;"><br></p>

<ul>
  <li>
    <p>Input: multiple channels of 2D arrays. in total K channels</p>
  </li>
  <li>
    <p>Kernel: small 2D array of weights</p>

    <ul>
      <li>4D array for all the kernels in one layer, which means for all k and j: (h,l, K, J)</li>
    </ul>
  </li>
  <li>
    <p>Filter: a collection of kernels</p>

    <ul>
      <li>
        <p>the number of kernels in a filter = the number of input channels = K</p>
      </li>
      <li>
        <p>each channel will have one unique kernel to slide through</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Output channels: equivalent to the neurons in that layer. in total J channels</p>

    <ul>
      <li>1 filter only yields 1 output channel</li>
    </ul>
  </li>
  <li>
    <p>There’s only 1 bias term for each filter</p>
  </li>
</ul>

<p>Example input has 3 channels (K = 3), each channel is 5x5. Kernel is 3x3.</p>

<p>Step 1: Each unique kernel in a filter will go through each input channel and yield a processed version of that input channel. So we will get K unique kernels.</p>

<div style="font-size: 80%; color: #808080; text-align:center; font-style: italic;">
<img src="/assets/img/dl4mir/cnn1.gif" alt="CNN 1" width="100%" style="padding-bottom:0.5em;">
Reference image is from Irhum Shafkat's Medium article.</div>

<p>Step 2: Sum over all the processed versions to get one output channel</p>

<p><img src="/assets/img/dl4mir/cnn2.gif" alt="CNN 2" width="100%" style="padding-bottom:0.5em;"></p>

<p>Step 3: Add in the bias term for this filter to get the final output channel. Note this will be y<sub>j</sub></p>

<p><img src="/assets/img/dl4mir/cnn3.gif" alt="CNN 3" width="50%" style="padding-bottom:0.5em;"><br></p>

<p><strong>Subsampling:</strong></p>

<p>Usually convolutional layers are used with pooling layers. For example, a maxpool.</p>

<ul>
  <li>
    <p>Pooling layer reduces the size of feature maps by downsampling them with an operation.</p>

    <ul>
      <li>
        <p>Max function tests if there exists an activation in a local region, but discards the precise location of the activation</p>
      </li>
      <li>
        <p>Average operation usually not used, but it is applied globally after the last convolutional layer to summarize the feature map activation on the whole area of input, when input size varies</p>
      </li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/dl4mir/image17.png" alt="formula" width="80%" style="padding-bottom:0.5em;"><br></p>

<h3 id="cnn--music">CNN &amp; Music</h3>

<ul>
  <li>
    <p>Example use cases where CNN could be used in music:</p>

    <ul>
      <li>
        <p>1D convolutional kernel that learns fundamental frequencies from raw audio samples</p>
      </li>
      <li>
        <p>Apply 2D convolutional layers to 2D time-frequency representations</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Kernel size: determines maximum size of a component that the kernel can precisely capture in the layer</p>

    <ul>
      <li>
        <p>Not too small: should at least be big enough to capture the difference between the two patterns you are trying to capture</p>
      </li>
      <li>
        <p>When the kernel is big, best to use it with a stacked convolution layers with subsamplings so that small distortions can be allowed. This is because kernel does not allow invariance in it.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>CNN is shift invariant, which means the output will shift with the input but it stays otherwise unchanged. To put it plainly, a cat can be moved to another location of the image, but CNN will still be able to detect the cat.</p>
  </li>
</ul>

<p><br></p>

<hr>
<p><br></p>

<h3 id="resources">Resources:</h3>

<p>Kunlun Bai’s Medium article about different types of convolutions in CNNs <a href="https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215" target="_blank" rel="noopener noreferrer">here</a></p>

<p>Irhum Shafkat’s Medium article with awesome visualizations <a href="https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1" target="_blank" rel="noopener noreferrer">here</a></p>

<p>Chris Olah’s blog about CNNs <a href="http://colah.github.io/posts/2014-07-Conv-Nets-Modular/" target="_blank" rel="noopener noreferrer">here</a></p>

<p>GA Tech’s Polo Club of Data Science’s Interactive CNN learner in browser <a href="https://poloclub.github.io/cnn-explainer/#article-convolution" target="_blank" rel="noopener noreferrer">here</a></p>

  </article>

</div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 Aleksandra T. Ma. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. All photos &amp; opinions my own.
Last updated: December 02, 2025.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>
